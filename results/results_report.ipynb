{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Customer Churn Prediction Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# path to project root\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as ut\n",
    "import src.preprocess as pp\n",
    "import src.config as cf\n",
    "import src.train as tn\n",
    "import src.evaluate as et\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = ut.load_data(cf.paths['data_raw'])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target - Feature and Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.drop(columns = 'Churn', axis = 1)\n",
    "y = raw_data['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = cf.test_size, random_state = cf.random_state)\n",
    "\n",
    "# hard copies for error analysis\n",
    "X_train_plain = X_train.copy()\n",
    "X_test_plain = X_test.copy()\n",
    "y_train_plain = y_train.copy()\n",
    "y_test_plain = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessing pipeline for target variable\n",
    "target_preprocessing_pipeline = pp.TargetPreprocess()\n",
    "\n",
    "# create preprocessing pipeline for feature variables\n",
    "feature_preprocessing_pipeline = Pipeline(steps = [\n",
    "    ('feature_selection', pp.FeatureSelector()),\n",
    "    ('data_cleaning', pp.DataCleaning()),\n",
    "    ('feature_engineering', pp.FeatureEngineering()),\n",
    "    ('outlier_detection', pp.OutlierDetector()),\n",
    "    ('missing_values', pp.MissingValuesHandler()),\n",
    "    ('encoding', pp.CategoricalEncoder()),\n",
    "    ('scaling', pp.Scaling())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target_preprocessing_pipeline.fit_transform(y_train)\n",
    "y_test = target_preprocessing_pipeline.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Variable Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_preprocessing_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feature_preprocessing_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fittting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fitting\n",
    "lr_results = tn.train_model(\n",
    "    model_name = 'LogisticRegression',\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    mode = 'manual'\n",
    "    )\n",
    "\n",
    "# train score\n",
    "lr_train_score = lr_results['cv_train_score']\n",
    "\n",
    "# validation score\n",
    "lr_val_score = lr_results['cv_val_score']\n",
    "\n",
    "# best model\n",
    "lr_best_model = lr_results['best_model']\n",
    "\n",
    "# best parameters\n",
    "lr_best_params = lr_results['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overfit Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores_df = pd.DataFrame(\n",
    "    [lr_train_score, lr_val_score],\n",
    "    index = ['Train Score', 'Validation Score']\n",
    ")\n",
    "\n",
    "lr_scores_df = lr_scores_df.style.format({\n",
    "    'mean' : '{:.2%}',\n",
    "    'std': '{:.2%}'\n",
    "})\n",
    "\n",
    "lr_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    list(lr_best_params.items()),\n",
    "    columns = ['Hyperparameter', 'Value']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values predictions\n",
    "y_pred = lr_best_model.predict(X_test)\n",
    "\n",
    "# probabability predictions\n",
    "y_pred_proba = lr_best_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.generate_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision - Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_precision_recall(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified = X_test_plain[y_test != y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fittting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fitting\n",
    "svm_results = tn.train_model(\n",
    "    model_name = 'SVM',\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    mode = 'manual'\n",
    "    )\n",
    "\n",
    "# train score\n",
    "svm_train_score = svm_results['cv_train_score']\n",
    "\n",
    "# validation score\n",
    "svm_val_score = svm_results['cv_val_score']\n",
    "\n",
    "# best model\n",
    "svm_best_model = svm_results['best_model']\n",
    "\n",
    "# best parameters\n",
    "svm_best_params = svm_results['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overfit Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores_df = pd.DataFrame(\n",
    "    [svm_train_score, svm_val_score],\n",
    "    index = ['Train Score', 'Validation Score']\n",
    ")\n",
    "\n",
    "svm_scores_df = svm_scores_df.style.format({\n",
    "    'mean' : '{:.2%}',\n",
    "    'std': '{:.2%}'\n",
    "})\n",
    "\n",
    "svm_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    list(svm_best_params.items()),\n",
    "    columns = ['Hyperparameter', 'Value']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values predictions\n",
    "y_pred = svm_best_model.predict(X_test)\n",
    "\n",
    "# probabability predictions\n",
    "y_pred_proba = svm_best_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.generate_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision - Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_precision_recall(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified = X_test_plain[y_test != y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fitting\n",
    "rf_results = tn.train_model(\n",
    "    model_name = 'RandomForest',\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    mode = 'manual' \n",
    ")\n",
    "\n",
    "# train score\n",
    "rf_train_score = rf_results['cv_train_score']\n",
    "\n",
    "# validation score\n",
    "rf_val_score = rf_results['cv_val_score']\n",
    "\n",
    "# best model\n",
    "rf_best_model = rf_results['best_model']\n",
    "\n",
    "# best parameters\n",
    "rf_best_params = rf_results['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overfit Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores_df = pd.DataFrame(\n",
    "    [rf_train_score, rf_val_score],\n",
    "    index = ['Train Score', 'Validation Score']\n",
    ")\n",
    "\n",
    "rf_scores_df = rf_scores_df.style.format({\n",
    "    'mean' : '{:.2%}',\n",
    "    'std': '{:.2%}'\n",
    "})\n",
    "\n",
    "rf_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    list(rf_best_params.items()),\n",
    "    columns = ['Hyperparameter', 'Value']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('dark')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "importances = rf_best_model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by = 'Importance', ascending = False)\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.barplot(\n",
    "    x = 'Importance', \n",
    "    y = 'Feature',\n",
    "    data = importance_df,\n",
    "    palette = 'viridis',\n",
    "    hue = 'Feature',\n",
    "    dodge = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values predictions\n",
    "y_pred = rf_best_model.predict(X_test)\n",
    "\n",
    "# probabability predictions\n",
    "y_pred_proba = rf_best_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.generate_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision - Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_precision_recall(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "missclassified = X_test_plain[y_test != y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.uniqueness_categorical_columns(missclassified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fitting\n",
    "gb_results = tn.train_model(\n",
    "    model_name = 'GradientBoosting',\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    mode = 'manual' \n",
    ")\n",
    "\n",
    "# train score\n",
    "gb_train_score = gb_results['cv_train_score']\n",
    "\n",
    "# validation score\n",
    "gb_val_score = gb_results['cv_val_score']\n",
    "\n",
    "# best model\n",
    "gb_best_model = gb_results['best_model']\n",
    "\n",
    "# best parameters\n",
    "gb_best_params = gb_results['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overfit Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_scores_df = pd.DataFrame(\n",
    "    [gb_train_score, gb_val_score],\n",
    "    index = ['Train Score', 'Validation Score']\n",
    ")\n",
    "\n",
    "gb_scores_df = gb_scores_df.style.format({\n",
    "    'mean' : '{:.2%}',\n",
    "    'std': '{:.2%}'\n",
    "})\n",
    "\n",
    "gb_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    list(gb_best_params.items()),\n",
    "    columns = ['Hyperparameter', 'Value']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('dark')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "importances = gb_best_model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by = 'Importance', ascending = False)\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.barplot(\n",
    "    x = 'Importance', \n",
    "    y = 'Feature',\n",
    "    data = importance_df,\n",
    "    palette = 'viridis',\n",
    "    hue = 'Feature',\n",
    "    dodge = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values predictions\n",
    "y_pred = gb_best_model.predict(X_test)\n",
    "\n",
    "# probabability predictions\n",
    "y_pred_proba = gb_best_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.generate_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision - Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.plot_precision_recall(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
